{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f21a30-97a2-4a2b-93c8-5be6abc36114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling, \n",
    "    AutoTokenizer\n",
    ")\n",
    "import torch\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fee574e-4bab-4371-8536-97892dca8398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acast\\AppData\\Local\\Temp\\ipykernel_13876\\2397495945.py:1: ParserWarning: Skipping line 8395: expected 1 fields, saw 2\n",
      "Skipping line 8396: expected 1 fields, saw 2\n",
      "Skipping line 8397: expected 1 fields, saw 2\n",
      "Skipping line 8398: expected 1 fields, saw 2\n",
      "Skipping line 8399: expected 1 fields, saw 2\n",
      "Skipping line 31600: expected 1 fields, saw 2\n",
      "Skipping line 74442: expected 1 fields, saw 2\n",
      "Skipping line 74443: expected 1 fields, saw 2\n",
      "Skipping line 74444: expected 1 fields, saw 2\n",
      "Skipping line 74445: expected 1 fields, saw 2\n",
      "Skipping line 74446: expected 1 fields, saw 2\n",
      "Skipping line 74447: expected 1 fields, saw 2\n",
      "Skipping line 74448: expected 1 fields, saw 2\n",
      "Skipping line 74449: expected 1 fields, saw 2\n",
      "Skipping line 74450: expected 1 fields, saw 2\n",
      "Skipping line 74451: expected 1 fields, saw 2\n",
      "Skipping line 74452: expected 1 fields, saw 2\n",
      "Skipping line 74453: expected 1 fields, saw 2\n",
      "Skipping line 74454: expected 1 fields, saw 2\n",
      "Skipping line 74455: expected 1 fields, saw 2\n",
      "Skipping line 74456: expected 1 fields, saw 2\n",
      "Skipping line 89163: expected 1 fields, saw 2\n",
      "Skipping line 89164: expected 1 fields, saw 2\n",
      "Skipping line 89165: expected 1 fields, saw 2\n",
      "Skipping line 89166: expected 1 fields, saw 2\n",
      "Skipping line 89167: expected 1 fields, saw 2\n",
      "Skipping line 89168: expected 1 fields, saw 2\n",
      "Skipping line 89169: expected 1 fields, saw 2\n",
      "Skipping line 89170: expected 1 fields, saw 2\n",
      "Skipping line 89171: expected 1 fields, saw 2\n",
      "Skipping line 89172: expected 1 fields, saw 2\n",
      "Skipping line 89173: expected 1 fields, saw 2\n",
      "Skipping line 100984: expected 1 fields, saw 2\n",
      "Skipping line 101666: expected 1 fields, saw 2\n",
      "Skipping line 101669: expected 1 fields, saw 2\n",
      "Skipping line 101677: expected 1 fields, saw 2\n",
      "Skipping line 153058: expected 1 fields, saw 5\n",
      "Skipping line 153059: expected 1 fields, saw 5\n",
      "Skipping line 153060: expected 1 fields, saw 5\n",
      "Skipping line 153061: expected 1 fields, saw 5\n",
      "Skipping line 153062: expected 1 fields, saw 5\n",
      "Skipping line 153063: expected 1 fields, saw 5\n",
      "Skipping line 153064: expected 1 fields, saw 5\n",
      "Skipping line 153065: expected 1 fields, saw 5\n",
      "Skipping line 153066: expected 1 fields, saw 5\n",
      "Skipping line 153067: expected 1 fields, saw 5\n",
      "Skipping line 153069: expected 1 fields, saw 5\n",
      "Skipping line 166558: expected 1 fields, saw 2\n",
      "Skipping line 166559: expected 1 fields, saw 2\n",
      "Skipping line 166560: expected 1 fields, saw 2\n",
      "Skipping line 166561: expected 1 fields, saw 2\n",
      "Skipping line 166562: expected 1 fields, saw 2\n",
      "Skipping line 169013: expected 1 fields, saw 2\n",
      "Skipping line 171146: expected 1 fields, saw 4\n",
      "Skipping line 203495: expected 1 fields, saw 2\n",
      "Skipping line 203496: expected 1 fields, saw 2\n",
      "Skipping line 203497: expected 1 fields, saw 2\n",
      "Skipping line 203498: expected 1 fields, saw 2\n",
      "Skipping line 203499: expected 1 fields, saw 2\n",
      "Skipping line 203501: expected 1 fields, saw 2\n",
      "Skipping line 203502: expected 1 fields, saw 2\n",
      "Skipping line 203503: expected 1 fields, saw 2\n",
      "Skipping line 203504: expected 1 fields, saw 2\n",
      "Skipping line 203510: expected 1 fields, saw 2\n",
      "Skipping line 203511: expected 1 fields, saw 2\n",
      "Skipping line 203512: expected 1 fields, saw 2\n",
      "Skipping line 203513: expected 1 fields, saw 2\n",
      "Skipping line 203516: expected 1 fields, saw 2\n",
      "Skipping line 203517: expected 1 fields, saw 2\n",
      "Skipping line 203518: expected 1 fields, saw 2\n",
      "Skipping line 203519: expected 1 fields, saw 2\n",
      "Skipping line 203524: expected 1 fields, saw 2\n",
      "Skipping line 203525: expected 1 fields, saw 2\n",
      "Skipping line 203526: expected 1 fields, saw 2\n",
      "Skipping line 203527: expected 1 fields, saw 2\n",
      "Skipping line 203528: expected 1 fields, saw 2\n",
      "Skipping line 203531: expected 1 fields, saw 2\n",
      "Skipping line 203532: expected 1 fields, saw 2\n",
      "Skipping line 203533: expected 1 fields, saw 2\n",
      "Skipping line 203534: expected 1 fields, saw 2\n",
      "Skipping line 203538: expected 1 fields, saw 2\n",
      "Skipping line 203540: expected 1 fields, saw 2\n",
      "Skipping line 203541: expected 1 fields, saw 2\n",
      "Skipping line 203542: expected 1 fields, saw 2\n",
      "Skipping line 203543: expected 1 fields, saw 2\n",
      "Skipping line 203545: expected 1 fields, saw 2\n",
      "Skipping line 203546: expected 1 fields, saw 2\n",
      "Skipping line 203550: expected 1 fields, saw 2\n",
      "Skipping line 203551: expected 1 fields, saw 2\n",
      "Skipping line 203552: expected 1 fields, saw 2\n",
      "Skipping line 203553: expected 1 fields, saw 2\n",
      "Skipping line 203559: expected 1 fields, saw 2\n",
      "Skipping line 203560: expected 1 fields, saw 2\n",
      "Skipping line 203561: expected 1 fields, saw 2\n",
      "Skipping line 203562: expected 1 fields, saw 2\n",
      "Skipping line 203567: expected 1 fields, saw 2\n",
      "Skipping line 203568: expected 1 fields, saw 2\n",
      "Skipping line 203569: expected 1 fields, saw 2\n",
      "Skipping line 203570: expected 1 fields, saw 2\n",
      "Skipping line 217757: expected 1 fields, saw 3\n",
      "Skipping line 217758: expected 1 fields, saw 3\n",
      "Skipping line 217759: expected 1 fields, saw 3\n",
      "Skipping line 217760: expected 1 fields, saw 3\n",
      "Skipping line 217761: expected 1 fields, saw 3\n",
      "Skipping line 217762: expected 1 fields, saw 3\n",
      "Skipping line 217763: expected 1 fields, saw 3\n",
      "Skipping line 231023: expected 1 fields, saw 2\n",
      "Skipping line 231024: expected 1 fields, saw 2\n",
      "Skipping line 231058: expected 1 fields, saw 2\n",
      "Skipping line 231067: expected 1 fields, saw 2\n",
      "Skipping line 231068: expected 1 fields, saw 2\n",
      "Skipping line 231069: expected 1 fields, saw 2\n",
      "Skipping line 231070: expected 1 fields, saw 2\n",
      "Skipping line 231071: expected 1 fields, saw 2\n",
      "Skipping line 231072: expected 1 fields, saw 2\n",
      "Skipping line 231075: expected 1 fields, saw 2\n",
      "Skipping line 231076: expected 1 fields, saw 2\n",
      "Skipping line 231077: expected 1 fields, saw 2\n",
      "Skipping line 231078: expected 1 fields, saw 2\n",
      "Skipping line 231079: expected 1 fields, saw 2\n",
      "\n",
      "  df = pd.read_table(\"Dataset/chat.txt\", header = None, on_bad_lines = \"warn\", names = [\"text\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/26/17, 5:19 PM - Linda Roldán: Hoola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/26/17, 5:19 PM - Linda Roldán: Bebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/26/17, 5:46 PM - Alejandro Castellanos: Hola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/26/17, 5:46 PM - Alejandro Castellanos: Y es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/26/17, 5:54 PM - Linda Roldán: Este es mi nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231352</th>\n",
       "      <td>7/22/25, 3:46 PM - Alejandro Castellanos: pens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231353</th>\n",
       "      <td>7/22/25, 3:46 PM - Alejandro Castellanos: y to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231354</th>\n",
       "      <td>7/22/25, 3:51 PM - Linda Roldán: &lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231355</th>\n",
       "      <td>7/22/25, 4:07 PM - Alejandro Castellanos: y tú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231356</th>\n",
       "      <td>7/22/25, 4:13 PM - Linda Roldán: Clase b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231357 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0                  6/26/17, 5:19 PM - Linda Roldán: Hoola\n",
       "1                   6/26/17, 5:19 PM - Linda Roldán: Bebe\n",
       "2       6/26/17, 5:46 PM - Alejandro Castellanos: Hola...\n",
       "3       6/26/17, 5:46 PM - Alejandro Castellanos: Y es...\n",
       "4       6/26/17, 5:54 PM - Linda Roldán: Este es mi nu...\n",
       "...                                                   ...\n",
       "231352  7/22/25, 3:46 PM - Alejandro Castellanos: pens...\n",
       "231353  7/22/25, 3:46 PM - Alejandro Castellanos: y to...\n",
       "231354   7/22/25, 3:51 PM - Linda Roldán: <Media omitted>\n",
       "231355  7/22/25, 4:07 PM - Alejandro Castellanos: y tú...\n",
       "231356           7/22/25, 4:13 PM - Linda Roldán: Clase b\n",
       "\n",
       "[231357 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"Dataset/chat.txt\", header = None, on_bad_lines = \"warn\", names = [\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb9411e-a5d5-4837-a25e-8c7d8e9d0a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231357, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0343d15a-5623-4dfb-9841-7d138bce89f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/26/17, 5:19 PM - Linda Roldán: Hoola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/26/17, 5:19 PM - Linda Roldán: Bebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/26/17, 5:46 PM - Alejandro Castellanos: Hola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/26/17, 5:46 PM - Alejandro Castellanos: Y es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/26/17, 5:54 PM - Linda Roldán: Este es mi nu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0             6/26/17, 5:19 PM - Linda Roldán: Hoola\n",
       "1              6/26/17, 5:19 PM - Linda Roldán: Bebe\n",
       "2  6/26/17, 5:46 PM - Alejandro Castellanos: Hola...\n",
       "3  6/26/17, 5:46 PM - Alejandro Castellanos: Y es...\n",
       "4  6/26/17, 5:54 PM - Linda Roldán: Este es mi nu..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Deleted Messages\n",
    "df = df[~df[\"text\"].str.contains(\"This message was deleted\")]\n",
    "\n",
    "# Delete all rows with \"Media omitted\" Message\n",
    "df = df[~df[\"text\"].str.contains(\"Media omitted\")]\n",
    "\n",
    "# Delete row with line breaks or without time data, string patter \"M - \" such as \"PM - \" or \"AM - \"\n",
    "df = df[df[\"text\"].str.contains(\"M - \")]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77604f1-1437-4a46-98fc-52ac0f69025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203079, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c930e7b5-8b5e-442e-9a1b-e65dd27f6737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Trim leading/trailing whitespace\n",
    "df['text'] = df['text'].str.strip()\n",
    "\n",
    "# 2) Split into “date_str” and “rest” on the first dash (hyphen or en-dash)\n",
    "parts = df['text'].str.split(r'\\s*[-–]\\s*', n=1, expand=True)\n",
    "df['date_str'], df['rest'] = parts[0], parts[1]\n",
    "\n",
    "# 3) Parse the date string (invalid formats become NaT)\n",
    "df['date'] = pd.to_datetime(\n",
    "    df['date_str'],\n",
    "    format='%m/%d/%y, %I:%M %p',\n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# 4) Split “rest” into “user” and “message” on the first colon\n",
    "usr_msg = df['rest'].str.split(r':\\s*', n=1, expand=True)\n",
    "df['user'], df['message'] = usr_msg[0], usr_msg[1]\n",
    "\n",
    "# 5) Drop the helper columns\n",
    "df = df.drop(columns=['date_str', 'rest'])\n",
    "\n",
    "#6) Drop nan\n",
    "df = df.dropna(subset=[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dcd2e19-b0ba-4df7-8cf3-937cafcd2b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/26/17, 5:19 PM - Linda Roldán: Hoola</td>\n",
       "      <td>2017-06-26 17:19:00</td>\n",
       "      <td>Linda Roldán</td>\n",
       "      <td>Hoola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/26/17, 5:19 PM - Linda Roldán: Bebe</td>\n",
       "      <td>2017-06-26 17:19:00</td>\n",
       "      <td>Linda Roldán</td>\n",
       "      <td>Bebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/26/17, 5:46 PM - Alejandro Castellanos: Hola...</td>\n",
       "      <td>2017-06-26 17:46:00</td>\n",
       "      <td>Alejandro Castellanos</td>\n",
       "      <td>Hola chiquita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/26/17, 5:46 PM - Alejandro Castellanos: Y es...</td>\n",
       "      <td>2017-06-26 17:46:00</td>\n",
       "      <td>Alejandro Castellanos</td>\n",
       "      <td>Y este número¿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/26/17, 5:54 PM - Linda Roldán: Este es mi nu...</td>\n",
       "      <td>2017-06-26 17:54:00</td>\n",
       "      <td>Linda Roldán</td>\n",
       "      <td>Este es mi numero anterior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                date  \\\n",
       "0             6/26/17, 5:19 PM - Linda Roldán: Hoola 2017-06-26 17:19:00   \n",
       "1              6/26/17, 5:19 PM - Linda Roldán: Bebe 2017-06-26 17:19:00   \n",
       "2  6/26/17, 5:46 PM - Alejandro Castellanos: Hola... 2017-06-26 17:46:00   \n",
       "3  6/26/17, 5:46 PM - Alejandro Castellanos: Y es... 2017-06-26 17:46:00   \n",
       "4  6/26/17, 5:54 PM - Linda Roldán: Este es mi nu... 2017-06-26 17:54:00   \n",
       "\n",
       "                    user                     message  \n",
       "0           Linda Roldán                       Hoola  \n",
       "1           Linda Roldán                        Bebe  \n",
       "2  Alejandro Castellanos               Hola chiquita  \n",
       "3  Alejandro Castellanos              Y este número¿  \n",
       "4           Linda Roldán  Este es mi numero anterior  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175aab0b-fece-4d9c-b3cc-13bddf67374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "other = df[df[\"user\"] != \"Alejandro Castellanos\"].reset_index(drop = True)\n",
    "mine = df[df[\"user\"] == \"Alejandro Castellanos\"].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa7ff69-5b52-4e85-9efe-8849068e122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116957, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb0ff19d-3bbb-49b8-8fb9-6d0f470df0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86117, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27b7b4c-6d16-4edd-95ab-432ca471b323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hoola Bebe</td>\n",
       "      <td>Hola chiquita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Este es mi numero anterior</td>\n",
       "      <td>A síii, y que cel tienes?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El mio le mande a arreglar</td>\n",
       "      <td>A síii???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Siiii</td>\n",
       "      <td>Muy bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.000 pero lo estoy pagando a plazos</td>\n",
       "      <td>Y quedó bien?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>No se</td>\n",
       "      <td>Por qué no sabes?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No tiene corrector de ortografia</td>\n",
       "      <td>A eso es lo de menos :p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nooo En mi situacion es lo de mas</td>\n",
       "      <td>Pero eso es de configuración</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asiii Y como hagoo para configurarlo</td>\n",
       "      <td>Espérate busco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bueno</td>\n",
       "      <td>Entra a configuración, busca Teclado, seleccio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 context  \\\n",
       "0                             Hoola Bebe   \n",
       "1             Este es mi numero anterior   \n",
       "2             El mio le mande a arreglar   \n",
       "3                                  Siiii   \n",
       "4  30.000 pero lo estoy pagando a plazos   \n",
       "5                                  No se   \n",
       "6       No tiene corrector de ortografia   \n",
       "7      Nooo En mi situacion es lo de mas   \n",
       "8   Asiii Y como hagoo para configurarlo   \n",
       "9                                  Bueno   \n",
       "\n",
       "                                               reply  \n",
       "0                                      Hola chiquita  \n",
       "1                          A síii, y que cel tienes?  \n",
       "2                                          A síii???  \n",
       "3                                           Muy bien  \n",
       "4                                      Y quedó bien?  \n",
       "5                                  Por qué no sabes?  \n",
       "6                            A eso es lo de menos :p  \n",
       "7                       Pero eso es de configuración  \n",
       "8                                     Espérate busco  \n",
       "9  Entra a configuración, busca Teclado, seleccio...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_list = []\n",
    "context_msgs = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    if row[\"user\"] != \"Alejandro Castellanos\":\n",
    "        # acumula mensaje de Linda\n",
    "        context_msgs.append(row[\"message\"])\n",
    "    else:\n",
    "        # aparece tu respuesta → creamos un par si hubo contexto\n",
    "        if context_msgs:\n",
    "            context = \" \".join(context_msgs)\n",
    "            reply   = row[\"message\"]\n",
    "            pairs_list.append({\n",
    "                \"context\": context,\n",
    "                \"reply\":   reply\n",
    "            })\n",
    "            context_msgs = []  # reiniciamos para el siguiente turno\n",
    "\n",
    "# Convertimos a DataFrame\n",
    "pairs = pd.DataFrame(pairs_list)\n",
    "\n",
    "# Vemos los primeros ejemplos\n",
    "pairs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9bdeb7-5d62-4a77-83fa-5c3598a2c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_ds = Dataset.from_pandas(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de8c36cd-46f8-4ad9-b83e-63fb18c52fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907fec5e4046469abbf37f40b941099b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [12982, 25, 367, 10513, 1355, 1350, 198, 20630, 25, 367, 5708, 442, 1557, 5350, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [12982, 25, 367, 10513, 1355, 1350, 198, 20630, 25, 367, 5708, 442, 1557, 5350, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]}\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Cargamos el tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "# Aseguramos que el token de padding sea el mismo que eos\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 5.3 Definimos función de tokenización\n",
    "def tokenize_fn(example):\n",
    "    # Construimos el prompt: ponemos 'User:' antes del contexto y 'Bot:' antes de la respuesta\n",
    "    prompt = f\"User: {example['context']}\\nBot:\"\n",
    "    # Tokenizamos prompt + reply juntos\n",
    "    enc = tokenizer(\n",
    "        prompt + \" \" + example[\"reply\"],\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    # En causal LM las etiquetas son los propios input_ids\n",
    "    enc[\"labels\"] = enc[\"input_ids\"].copy()\n",
    "    return enc\n",
    "\n",
    "# 5.4 Aplicamos el mapeo (esto puede tardar unos minutos)\n",
    "tokenized = hf_ds.map(\n",
    "    tokenize_fn,\n",
    "    batched=False,            # True si quieres tokenizar en lotes; con CPU pequeño mejor False\n",
    "    remove_columns=hf_ds.column_names\n",
    ")\n",
    "\n",
    "# Comprobamos un ejemplo tokenizado\n",
    "print(tokenized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "574ef0b8-8751-4586-a26b-975e1c0e5d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b4f84b-0bae-4162-bc72-9a015edfa5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acast\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1604: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of 🤗 Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='74' max='101452' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    74/101452 00:49 < 19:29:44, 1.44 it/s, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 31\u001b[0m\n\u001b[0;32m     23\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     24\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     25\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m     26\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized,      \u001b[38;5;66;03m# tu HF Dataset ya tokenizado\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 5) Entrenamos\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 6) Guardamos modelo y tokenizer\u001b[39;00m\n\u001b[0;32m     34\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./chat_style_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2206\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2204\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   2207\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   2208\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   2209\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   2210\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   2211\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\trainer.py:2607\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2603\u001b[0m         grad_norm \u001b[38;5;241m=\u001b[39m _grad_norm\n\u001b[0;32m   2605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_pre_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 2607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m   2609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_optimizer_step(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2611\u001b[0m \u001b[38;5;66;03m# get leaning rate before update\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\accelerate\\optimizer.py:179\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerate_step_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 179\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep(closure)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator_state\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mXLA:\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_state\u001b[38;5;241m.\u001b[39mis_xla_gradients_synced \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:124\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[0;32m    123\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(opt, opt\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:246\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    234\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    236\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    237\u001b[0m         group,\n\u001b[0;32m    238\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m         state_steps,\n\u001b[0;32m    244\u001b[0m     )\n\u001b[1;32m--> 246\u001b[0m     adam(\n\u001b[0;32m    247\u001b[0m         params_with_grad,\n\u001b[0;32m    248\u001b[0m         grads,\n\u001b[0;32m    249\u001b[0m         exp_avgs,\n\u001b[0;32m    250\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    251\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    252\u001b[0m         state_steps,\n\u001b[0;32m    253\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    254\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    255\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    256\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    257\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    258\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    259\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    260\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    261\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    262\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    263\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    264\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    265\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    266\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    267\u001b[0m         decoupled_weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoupled_weight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:147\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:933\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 933\u001b[0m func(\n\u001b[0;32m    934\u001b[0m     params,\n\u001b[0;32m    935\u001b[0m     grads,\n\u001b[0;32m    936\u001b[0m     exp_avgs,\n\u001b[0;32m    937\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    938\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    939\u001b[0m     state_steps,\n\u001b[0;32m    940\u001b[0m     amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m    941\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[0;32m    942\u001b[0m     beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[0;32m    943\u001b[0m     beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[0;32m    944\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    945\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[0;32m    946\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    947\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[0;32m    948\u001b[0m     capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m    949\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[0;32m    950\u001b[0m     grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[0;32m    951\u001b[0m     found_inf\u001b[38;5;241m=\u001b[39mfound_inf,\n\u001b[0;32m    952\u001b[0m     decoupled_weight_decay\u001b[38;5;241m=\u001b[39mdecoupled_weight_decay,\n\u001b[0;32m    953\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\optim\\adam.py:525\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[0m\n\u001b[0;32m    523\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 525\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    527\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[0;32m    529\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1) Carga el modelo en PyTorch\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "\n",
    "# 2) Collator para causal LM (no hacemos MLM)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# 3) Parámetros de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./chat_style_model\",\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=100,\n",
    "    dataloader_num_workers=4,\n",
    "    save_steps=500,\n",
    "    no_cuda=True       # fuerza CPU\n",
    ")\n",
    "\n",
    "# 4) Creamos el Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized,      # tu HF Dataset ya tokenizado\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 5) Entrenamos\n",
    "trainer.train()\n",
    "\n",
    "# 6) Guardamos modelo y tokenizer\n",
    "trainer.save_model(\"./chat_style_model\")\n",
    "tokenizer.save_pretrained(\"./chat_style_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
